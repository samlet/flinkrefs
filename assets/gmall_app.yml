version: "1"

tables:
    product_stats:
        create: |
            CREATE TABLE product_stats (spu_name STRING,
                click_ct BIGINT,
                cart_ct BIGINT,
                order_ct BIGINT,
                stt STRING,edt STRING )
            WITH ( 'connector' = 'kafka',
                'topic' = 'dws_product_stats',
                'properties.bootstrap.servers' = 'localhost:9092',
                'properties.group.id' = 'keyword_stats_app',
                'format' = 'json',
                'scan.startup.mode' = 'latest-offset' )

    page_view:
        create: |
            CREATE TABLE page_view (
                common MAP<STRING, STRING>,
                page MAP<STRING, STRING>,
                ts BIGINT,
                rowtime as TO_TIMESTAMP(FROM_UNIXTIME(ts/1000,'yyyy-MM-dd HH:mm:ss')),
                WATERMARK FOR rowtime AS rowtime - INTERVAL '2' SECOND)
            WITH ( 'connector' = 'kafka',
                'topic' = 'dwd_page_log',
                'properties.bootstrap.servers' = 'localhost:9092',
                'properties.group.id' = 'keywordstats_app_group',
                'format' = 'json',
                'scan.startup.mode' = 'latest-offset' )

pipes:
    # 从商品统计中获取关键词
    # sink to clickhouse:
    # insert into keyword_stats_0820(keyword,ct,source,stt,edt,ts) values(?,?,?,?,?,?)
    keyword_stats_product:
        udf: [ik_analyze, keywordProductC2R]
        sql: |
            select keyword,ct,source,
                DATE_FORMAT(stt,'yyyy-MM-dd HH:mm:ss')  stt,
                DATE_FORMAT(edt,'yyyy-MM-dd HH:mm:ss') as edt,
                UNIX_TIMESTAMP()*1000 ts from product_stats  ,
                LATERAL TABLE(ik_analyze(spu_name)) as T(keyword) ,
                LATERAL TABLE(keywordProductC2R( click_ct ,cart_ct,order_ct)) as T2(ct,source)
