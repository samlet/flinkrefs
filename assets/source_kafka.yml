version: "1"

tables:
    user_behavior:
        create: |
            CREATE TABLE KafkaTable (
              `user_id` BIGINT,
              `item_id` BIGINT,
              `behavior` STRING,
              `ts` TIMESTAMP(3) METADATA FROM 'timestamp'
            ) WITH (
              'connector' = 'kafka',
              'topic' = 'user_behavior',
              'properties.bootstrap.servers' = 'localhost:9092',
              'properties.group.id' = 'testGroup',
              'scan.startup.mode' = 'earliest-offset',
              'format' = 'csv'
            );
        query:
            all:
                sql: select * from KafkaTable

    user_behavior_events:
        create: |
            CREATE TABLE KafkaTable (
              `event_time` TIMESTAMP(3) METADATA FROM 'timestamp',
              `partition` BIGINT METADATA VIRTUAL,
              `offset` BIGINT METADATA VIRTUAL,
              `user_id` BIGINT,
              `item_id` BIGINT,
              `behavior` STRING
            ) WITH (
              'connector' = 'kafka',
              'topic' = 'user_behavior',
              'properties.bootstrap.servers' = 'localhost:9092',
              'properties.group.id' = 'testGroup',
              'scan.startup.mode' = 'earliest-offset',
              'format' = 'csv'
            );

    # https://ci.apache.org/projects/flink/flink-docs-release-1.13/zh/docs/connectors/table/formats/json/
    user_behavior_json:
        create: |
            CREATE TABLE user_behavior (
              user_id BIGINT,
              item_id BIGINT,
              category_id BIGINT,
              behavior STRING,
              ts TIMESTAMP(3)
            ) WITH (
             'connector' = 'kafka',
             'topic' = 'user_behavior',
             'properties.bootstrap.servers' = 'localhost:9092',
             'properties.group.id' = 'testGroup',
             'format' = 'json',
             'json.fail-on-missing-field' = 'false',
             'json.ignore-parse-errors' = 'true'
            )

    products_maxwell:
        create: |
            CREATE TABLE topic_products (
              -- schema is totally the same to the MySQL "products" table
              id BIGINT,
              name STRING,
              description STRING,
              weight DECIMAL(10, 2)
            ) WITH (
             'connector' = 'kafka',
             'topic' = 'products_binlog',
             'properties.bootstrap.servers' = 'localhost:9092',
             'properties.group.id' = 'testGroup',
             'format' = 'maxwell-json'
            )

    user_page_input:
        create: |
            CREATE TABLE input_kafka (
              user_id BIGINT,
              page_id BIGINT,
              status STRING
            ) WITH (
              'connector' = 'kafka',
              'topic' = 'input_kafka',
              'properties.bootstrap.servers' = 'localhost:9092',
              'properties.group.id' = 'default',
              'scan.startup.mode' = 'latest-offset',
              'format' = 'csv'
            )

    user_page_output:
        create: |
            CREATE TABLE output_kafka (
              user_id BIGINT,
              page_id BIGINT,
              status STRING
            ) WITH (
              'connector' = 'kafka',
              'topic' = 'output_kafka',
              'properties.bootstrap.servers' = 'localhost:9092',
              'format' = 'json',
              'sink.partitioner' = 'round-robin'
            )

pipes:
    pick_success:
        sql: |
            insert into output_kafka
                select user_id, page_id, status
                    from input_kafka
                    where status = 'success'

